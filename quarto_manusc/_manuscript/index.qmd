---
title: Trabajo Final de Análisis Estadístico
subtitle: Maestría en Ciencia de Datos (UNAJ)
authors:
  - name: Facundo Cuba
  - name: Leticia Nanini
  - name: Mauro Cejas Marcovecchio
  - name: Yesica Travasso
date: last-modified
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)

library(tidyverse)
library(lmtest)
library(coin)
library(gt)

```

## Descripción

El objetivo del siguiente trabajo es el procesamiento de datos y análisis estadísticos del dataset provisto por el Sistema de Información y Gestión Agrometeorológica (SIGA), del [Instituto Nacional de Tecnología Agropecuaria (INTA)](https://siga.inta.gob.ar/). Esta base de datos contiene información agrometeorológica de la ciudad de Castelar, Provincia de Buenos Aires, Argentina.

## 1. Estadística descriptiva

En primer lugar, vamos a poder tener una primera aproximación a los datos a partir del paquete ReadR, ya que el delimitador utilizado para separar las columnas es ";" y "." como separador decimal.

```{r}

# Cargamos los datos del grupo

archivo <- "datos/01_Buenos_Aires_Castelar.csv"

df <- read_delim(archivo, 
                 delim = ";", 
                 locale = locale(decimal_mark = "."))


```

Así, podremos ver que tendremos 472 observaciones con 5 variables:

-   **Fecha**(en formato fecha): Día de medición.

-   **Temperatura_Abrigo_150cm** (en formato número): La temperatura de abrigo es aquella medida en el abrigo meteorológico, que protege los instrumentos de medición de la radiación directa del sol, de la radiación terrestre nocturna, precipitación y condensación, entre otros. Su piso de abrigo es la altura a la que es medida la temperatura. En este caso, es de 150 cm por sobre el nivel del suelo.

-   **Humedad Media** (en formato número): La humedad relativa es la relación entre la presión parcial del vapor de agua y la presión de vapor de equilibrio del agua a una temperatura dada.

-   **Presión Media** (en formato número): La presión atmosférica es la fuerza por unidad de superficie que ejerce el aire que forma la atmósfera sobre la superficie terrestre.

-   **Radiación Global** (en formato número): La radiación global es la radiación solar que recibe la superficie terrestre

```{r}

head(df)

```

También, podremos realizar una descripción numérica de los datos a partir de sus principales medidas de estadística descriptiva:

```{r}

estadisticas <- df |>
  select(-Fecha) |>
  summarise(across(everything(), 
                  list(Minimo = min,
                       Q1 = ~quantile(., 0.25),
                       Mediana = median,
                       Media = mean, 
                       Q3 = ~quantile(., 0.75),
                       Maximo = max,
                       Desvio = sd,
                       IQR = IQR),
                  .names = "{.col}-{.fn}")) |>
  pivot_longer(everything(), 
               names_to = c("Variable", "Estadistica"), 
               names_sep = "-") |>
  pivot_wider(names_from = "Variable", values_from = "value")

estadisticas |>
  gt(rowname_col = "Estadistica",
     groupname_col = "")|>
  
  tab_stubhead(label = "Medidas") |>
  fmt_number(decimals = 2) |>
  
  cols_label(
    "Temperatura_Abrigo_150cm" = "Temperatura",
    "Humedad_Media" = "Humedad",
    "Presion_Media" = "Presion",
    "Radiacion_Global" = "Radiación"
  ) |>
  
  tab_style(
    style = cell_text(color = "black", 
                        weight = "bold"),
   locations = list(
        cells_stub(),
        cells_stubhead(),
        cells_column_labels(everything())))


```

Tales medidas podrán ser visualizadas de mejor manera a partir de gráficos de líneas tradicionales, suavizados, histogramas y box-plots.

```{r}

df_long <- df |>
  pivot_longer(cols = -Fecha, names_to = "Variable", values_to = "Valor")

ggplot(df_long, aes(x = Fecha, y = Valor, color = Variable)) +
  geom_line(show.legend = FALSE) +
  facet_wrap(~Variable, 
             scales = "free_y",
             labeller = labeller(
               Variable = c(
                 "Humedad_Media" = "Humedad media",
                 "Presion_Media" = "Presion media",
                 "Radiacion_Global" = "Radiación global",
                 "Temperatura_Abrigo_150cm" = "Temperatura de abrigo"))) +
  theme_minimal()

```

```{r}

ggplot(df_long, aes(x = Valor, fill = Variable)) +
  geom_histogram(bins = 10, show.legend = FALSE) +
  facet_wrap(~Variable, 
             scales = "free_x",
             labeller = labeller(
               Variable = c(
                 "Humedad_Media" = "Humedad media",
                 "Presion_Media" = "Presion media",
                 "Radiacion_Global" = "Radiación global",
                 "Temperatura_Abrigo_150cm" = "Temperatura de abrigo"))) +
  theme_minimal() +
  labs(y = "Cantidad")
  
```

```{r}

ggplot(df_long, aes(y = Valor, fill = Variable)) +
  geom_boxplot(show.legend = FALSE) +
  facet_wrap(~Variable, 
             scales = "free_y", 
             nrow = 1,
             labeller = labeller(
               Variable = c(
                 "Humedad_Media" = "Humedad media",
                 "Presion_Media" = "Presion media",
                 "Radiacion_Global" = "Radiación global",
                 "Temperatura_Abrigo_150cm" = "Temperatura"))) +
  theme_minimal() +
  labs(y = "Valor")

```

## 2. Test de Hipótesis - Regresión Lineal

Con el fin de tener una primera imagen acerca de las relaciones entre pares de las variables vamos a realizar una matriz de dispersión.

```{r}

df |>
  select(-Fecha) |>
  pairs(lower.panel = NULL,
        pch = 1,
        col = 'dodgerblue2',
        main = "Matriz de dispersión",
        las = 1,
        labels = c("Temperatura", "Humedad", "Presión", "Radiación"),
        gap = 0.5,
        rowlattop = FALSE,
        cex = 0.6,
        cex.labels = 1.2,
        cex.axis = 0.8,
        font.labels = 1)

```

Al ver el diagrama de dispersión entre los valores de temperatura de abrigo y la radiación global, podríamos inferir una correlación positiva entre ambas. Por tal motivo, vamos a realizar un modelo de regresión lineal simple para comprobarlo, en el que la Temperatura de Abrigo dependa del nivel de Radiación Global.

```{r}

modelo_regresion <- lm(Temperatura_Abrigo_150cm ~ Radiacion_Global, data = df)

summary(modelo_regresion)

```

A partir del resumen, podremos ver que los coeficientes del modelo serán una ordenada al origen de 11.81 y una pendiente de 0.41. Asimismo, graficaremos la regresión junto al cálculo de sus intervalos de confianza con un nivel del 95% (siendo notable la cantidad de observaciones que se encuentren por fuera de sus valores):

```{r}

print("Intervalos de confianza para los coeficientes:")

confint(modelo_regresion, level = .95)

```

```{r}

ggplot(df, aes(x = Radiacion_Global, y = Temperatura_Abrigo_150cm)) +
  geom_point(alpha = 0.5,
             color = "dodgerblue2") +
  geom_smooth(method = "lm", 
              se = TRUE) + 
  labs(x = "radiación global",
       y = "Temperatura del Abrigo") +
  theme_minimal()

```

Antes de empezar con el modelo, vamos a testear los supuestos de independencia y distribución de los que partimos para obtener sus correspondientes valores:

```{r}

# Residuos estandarizados vs Valores ajustados

plot(fitted(modelo_regresion),
     rstandard(modelo_regresion),
     col = "dodgerblue2",
     xlab = "Valores ajustados",
     ylab = "Residuos estandarizados")
abline(h=2, lty=2, lwd=1, col="black")
abline(h=-2, lty=2, lwd=1, col="black")
abline(h=0, col="black")

```

En este gráfico, vamos a observar la relación entre los valores ajustados y el residuo estandarizado. Podemos ver, así, que existen algunos valores atípicos que se ubican por fuera del rango (-2,2).

```{r}

# Residuos vs Valores ajustados

plot(fitted(modelo_regresion),
     resid(modelo_regresion),
     col = "dodgerblue2",
     xlab = "Valores ajustados",
     ylab = "Residuos")
abline(h = 0, lty = 2, col = "black") 
lines(lowess(fitted(modelo_regresion), 
             resid(modelo_regresion)), 
      col = "red")  

```

En relación al comportamiento de la varianza σ², veremos que la curva roja (útil para verificar la media cero) es relativamente plana y cercana a cero.

```{r}

# Gráfico Q-Q de normalidad

qqnorm(
  rstandard(modelo_regresion),
  col = "dodgerblue2",
  main = "",
  xlab = "Cuantiles teóricos (Distrib. Normal)",  
  ylab = "Residuos estandarizados"       
)
qqline(rstandard(modelo_regresion), col = "black", lty = 2)  

```

Finalmente, la curva de QQ-Plot nos permite observar que, con la información y evidencia disponible, la condición de normalidad ajusta bien, tomando apenas una forma de S en las puntas.

```{r}
summary(modelo_regresion)
```

De esta manera, no habiendo evidencia suficiente para rechazar las condiciones para el ruido aditivo E ∼ N(0, σ²), podemos considerar ambas variables X e Y como aleatorias y definir su coeficiente de correlación. Tal como vimos en el resumen del modelo:

```{r}

# Coeficiente de determinación (R-cuadrado)
print("Coeficiente de correlación (R²):")
print(summary(modelo_regresion)$r.squared, digits = 4)

```

Este coeficiente expresa cuánto de la variabilidad de los datos es explicada por el modelo de regresión lineal y su bajo valor nos hace dudar acerca de la representatividad del modelo que desarrollamos.

Aún así, verificamos que el p-valor de la pendiente ß₁ y de la ordenada al origen ß₀ son muy pequeños, lo que puede significar que exista una relación lineal entre ambas variables o que con un polinomio de mayor orden se obtenga un mejor resultado. Entonces, bajo la condición de normalidad, podremos realizar un test de hipótesis sobre la pendiente:

-   *H₀: ß₁ = 0*

-   *H₁: ß₁ ≠ 0*

```{r}

resumen <- summary(modelo_regresion)
coef_info <- resumen$coefficients["Radiacion_Global", ]

cat("Estadísticos:\n",
    "Coeficiente estimado:", round(coef_info["Estimate"], 2), "\n",
    "Error estándar:", round(coef_info["Std. Error"], 2), "\n",
    "Estadístico t:", round(coef_info["t value"], 2), "\n",
    "Grados libertad:", nrow(modelo_regresion$model) - 2, "\n",
    "p-valor:", format.pval(coef_info["Pr(>|t|)"]), "\n\n")

```

Como el p-valor es menor a un nivel de significatividad α del 5%, podemos comprobar que no existe evidencia suficiente para descartar la relación lineal entre las variables.

Así, tal como fue planteado anteriormente, vamos a realizar una regresión lineal múltiple incorporando el resto de las variables con las que contamos. En este caso, a diferencia de la regresión previa, tomaremos la Radiación Global como variable dependiente.

```{r}

modelo_regmult <- lm(Radiacion_Global ~ Temperatura_Abrigo_150cm + Humedad_Media + Presion_Media, data = df)

summary(modelo_regmult)

```

Podremos ver así que el R² será signficativamente mayor, explicando casi el 70% de la variabilidad de los datos, y el R² ajustado no será mucho menor al haber incorporado más variables al modelo. Cabe señalar que, en el caso de los coeficientes, el t-valor de la presión media es mayor que los demás, lo que podría cuestionarnos acerca de la significancia estadística que suma al modelo su incorporación.

## 3. Estadística no paramétrica

```{r}

# Test Paramétrico Original (Regresión Lineal)
cat("\n=== MÉTODO PARAMÉTRICO (REGRESIÓN LINEAL) ===\n")
summary_param <- summary(modelo_regresion)
coef_param <- summary_param$coefficients["Radiacion_Global", ]
p_param <- coef_param["Pr(>|t|)"]

cat("Coeficiente:", round(coef_param["Estimate"], 4),
    "\nValor-p:", format.pval(p_param, digits = 4), "\n")

# Test No Paramétrico (Correlación de Spearman)
cat("\n=== MÉTODO NO PARAMÉTRICO (SPEARMAN) ===\n")
cor_test <- cor.test(~ Radiacion_Global + Temperatura_Abrigo_150cm,
                     data = df,
                     method = "spearman",
                     exact = FALSE)  # Para n > 50

cat("Coeficiente Rho:", round(cor_test$estimate, 4),
    "\nValor-p:", format.pval(cor_test$p.value, digits = 4), "\n")

# Gráfico Comparativo
ggplot(df, aes(x = Temperatura_Abrigo_150cm, y = Radiacion_Global)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", color = "red", se = FALSE, linetype = "dashed") +
  geom_smooth(method = "loess", color = "blue", se = FALSE) +
  labs(title = "Comparación de Modelos",
       subtitle = "Rojo: Lineal (paramétrico) | Azul: LOESS (no paramétrico)",
       x = "Temperatura Abrigo (150cm)",
       y = "Radiación Global") +
  theme_minimal()

# Conclusión Comparativa
cat("\n=== CONCLUSIÓN COMPARATIVA ===\n")
if(p_param < 0.05 & cor_test$p.value < 0.05) {
  cat("Ambos métodos coinciden en que existe relación significativa (p < 0.05).\n")
  cat("El modelo paramétrico estima una pendiente de", round(coef_param["Estimate"], 4),
      "mientras que Spearman muestra una correlación de", round(cor_test$estimate, 4), "\n")
} else if(p_param >= 0.05 & cor_test$p.value >= 0.05) {
  cat("Ambos métodos coinciden en NO encontrar relación significativa (p > 0.05).\n")
} else {
  cat("Los métodos discrepan:\n")
  if(p_param < 0.05) {
    cat("- El método paramétrico encuentra relación significativa (p =", format.pval(p_param), ")\n")
  } else {
    cat("- El método paramétrico NO encuentra relación significativa (p =", format.pval(p_param), ")\n")
  }
  if(cor_test$p.value < 0.05) {
    cat("- El método no paramétrico encuentra relación significativa (p =", format.pval(cor_test$p.value), ")\n")
  } else {
    cat("- El método no paramétrico NO encuentra relación significativa (p =", format.pval(cor_test$p.value), ")\n")
  }
  cat("\nPosible causa: Supuestos del modelo paramétrico no se cumplen (ver residuos).\n")
}

```
